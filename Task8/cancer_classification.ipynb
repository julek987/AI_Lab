{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comparison of Classification Methods\n",
    "\n",
    "In this notebook, we will compare four classification techniques:\n",
    "1. **k-Nearest Neighbors (kNN)**\n",
    "2. **Support Vector Machine (SVM)**\n",
    "3. **Logistic Regression**\n",
    "4. **Linear Regression**\n",
    "\n",
    "We will use the Breast Cancer dataset from scikit-learn (a binary classification problem: **malignant** vs. **benign**)."
   ],
   "id": "56d5d5fb3fbd30aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:39:17.865297Z",
     "start_time": "2025-02-12T21:39:17.839739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ],
   "id": "7c2d6e8112ab80d0",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:39:17.904070Z",
     "start_time": "2025-02-12T21:39:17.870168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features (mean=0, variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "d6113595f80fbf33",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. k-Nearest Neighbors (kNN)\n",
    "\n",
    "**Theory:**  \n",
    "kNN is a non-parametric method that classifies a new data point based on the majority vote among its `k` nearest neighbors. It does not involve an explicit training phaseâ€”classification is performed at the time of prediction. However, this can be computationally expensive when the dataset is large, and the method is sensitive to the choice of `k` and feature scaling.\n",
    "\n",
    "Let's apply kNN with `k = 5`."
   ],
   "id": "c8ad2837606fee36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:39:17.947180Z",
     "start_time": "2025-02-12T21:39:17.919510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# kNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"### kNN Results ###\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_knn * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ],
   "id": "8a3f5e47277a8cd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### kNN Results ###\n",
      "Accuracy: 95.91%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94        63\n",
      "           1       0.96      0.97      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Support Vector Machine (SVM)\n",
    "\n",
    "**Theory:**  \n",
    "SVMs try to find a hyperplane that best separates the classes by maximizing the margin between them. With a linear kernel, SVM finds a straight-line (or hyperplane in higher dimensions) separator. SVMs are particularly effective in high-dimensional spaces and are robust with proper regularization.\n",
    "\n",
    "We use SVM with a linear kernel and a regularization parameter `C = 1.0`."
   ],
   "id": "6c473fdd38b2c4db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:39:17.987383Z",
     "start_time": "2025-02-12T21:39:17.976029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SVM Classifier\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"### SVM Results ###\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_svm * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ],
   "id": "830989947156720b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SVM Results ###\n",
      "Accuracy: 97.66%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        63\n",
      "           1       0.98      0.98      0.98       108\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Logistic Regression\n",
    "\n",
    "**Theory:**  \n",
    "Logistic Regression models the probability of class membership using the logistic (sigmoid) function. It outputs probabilities which can be thresholded (commonly at 0.5) to obtain class predictions."
   ],
   "id": "f55bd03d25c49b6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:39:18.023668Z",
     "start_time": "2025-02-12T21:39:17.999393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Logistic Regression Classifier\n",
    "logreg = LogisticRegression(max_iter=10000, random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test_scaled)\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "\n",
    "print(\"### Logistic Regression Results ###\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_logreg * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg))"
   ],
   "id": "5c092bddfe3e3e89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Logistic Regression Results ###\n",
      "Accuracy: 98.25%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98        63\n",
      "           1       0.99      0.98      0.99       108\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.98      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Linear Regression for Classification\n",
    "\n",
    "**Theory:**  \n",
    "Linear Regression is inherently designed for continuous outcomes. However, one can use it for classification by fitting a linear model to predict a continuous value and then thresholding the predictions (e.g., at 0.5) to decide class membership.  \n",
    "**Note:** This approach is not ideal because the model is not constrained to output probabilities between 0 and 1, but it serves as an instructive baseline."
   ],
   "id": "c077df0bd0908979"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:39:18.079303Z",
     "start_time": "2025-02-12T21:39:18.044728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Linear Regression Classifier (thresholded at 0.5)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_scaled, y_train)\n",
    "y_pred_linreg_cont = linreg.predict(X_test_scaled)\n",
    "y_pred_linreg = (y_pred_linreg_cont >= 0.5).astype(int)\n",
    "accuracy_linreg = accuracy_score(y_test, y_pred_linreg)\n",
    "\n",
    "print(\"### Linear Regression (Thresholded) Results ###\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_linreg * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_linreg))"
   ],
   "id": "4d24dea183f019e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Linear Regression (Thresholded) Results ###\n",
      "Accuracy: 95.32%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93        63\n",
      "           1       0.95      0.98      0.96       108\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.96      0.94      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6. Results\n",
    "\n",
    "Classification Accuracies:\n",
    "1. kNN Accuracy: 95.91%\n",
    "2. SVM Accuracy: 97.66%\n",
    "3. Logistic Regression Accuracy: 98.25%\n",
    "4. Linear Regression Accuracy (thresholded): 95.32%"
   ],
   "id": "378c08b09469ad84"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
